# =====================================================================
# å®Œæ•´ARCç¨‹åºåˆæˆé¡¹ç›®æ–‡ä»¶åŒ…
# åŸºäºPopperçš„å½’çº³é€»è¾‘ç¼–ç¨‹ä¸CEGISé›†æˆæ¡†æ¶
# =====================================================================

# é¡¹ç›®æ ¹ç›®å½•ç»“æ„ï¼š
"""
arc_synthesis_framework/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ README.md
â”œâ”€â”€ main.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ default.yaml
â”‚   â”œâ”€â”€ spatial.yaml
â”‚   â””â”€â”€ complex.yaml
â”œâ”€â”€ arc_synthesis_framework/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ synthesis_engine.py
â”‚   â”‚   â”œâ”€â”€ popper_interface.py
â”‚   â”‚   â”œâ”€â”€ anti_unification.py
â”‚   â”‚   â””â”€â”€ oracle.py
â”‚   â”œâ”€â”€ extraction/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ object_extractor.py
â”‚   â”‚   â”œâ”€â”€ spatial_predicates.py
â”‚   â”‚   â””â”€â”€ transformations.py
â”‚   â”œâ”€â”€ cegis/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ synthesizer.py
â”‚   â”‚   â”œâ”€â”€ verifier.py
â”‚   â”‚   â””â”€â”€ counterexample.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ arc_loader.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ logging.py
â”‚   â””â”€â”€ popper_files/
â”‚       â”œâ”€â”€ templates/
â”‚       â”‚   â”œâ”€â”€ basic_bias.pl
â”‚       â”‚   â”œâ”€â”€ basic_bk.pl
â”‚       â”‚   â””â”€â”€ spatial_bias.pl
â”‚       â”œâ”€â”€ bias/
â”‚       â”œâ”€â”€ background/
â”‚       â””â”€â”€ examples/
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ simple_tasks/
â”‚   â”‚   â””â”€â”€ color_change.json
â”‚   â””â”€â”€ demonstrations/
â”‚       â””â”€â”€ basic_usage.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_synthesis_engine.py
â”‚   â””â”€â”€ test_object_extractor.py
â””â”€â”€ docs/
    â””â”€â”€ README.md
"""

# =====================================================================
# 1. requirements.txt
# =====================================================================
REQUIREMENTS_TXT = """numpy>=1.21.0
scipy>=1.7.0
scikit-learn>=1.0.0
scikit-image>=0.18.0
pyyaml>=5.4.0
matplotlib>=3.4.0
networkx>=2.6.0
python-sat>=0.1.7.dev14
clingo>=5.5.0
"""

# =====================================================================
# 2. setup.py
# =====================================================================
SETUP_PY = """from setuptools import setup, find_packages

setup(
    name="arc-synthesis-framework",
    version="0.1.0",
    description="Popper-based Program Synthesis Framework for ARC Tasks",
    long_description=open("README.md").read(),
    long_description_content_type="text/markdown",
    author="ARC Research Team",
    author_email="research@arc-synthesis.com",
    url="https://github.com/arc-team/synthesis-framework",
    packages=find_packages(),
    install_requires=[
        "numpy>=1.21.0",
        "scipy>=1.7.0", 
        "scikit-learn>=1.0.0",
        "scikit-image>=0.18.0",
        "pyyaml>=5.4.0",
        "matplotlib>=3.4.0",
        "networkx>=2.6.0",
        "python-sat>=0.1.7.dev14",
        "clingo>=5.5.0"
    ],
    extras_require={
        "dev": ["pytest>=6.0", "black", "flake8", "mypy"],
        "docs": ["sphinx", "sphinx-rtd-theme"]
    },
    python_requires=">=3.8",
    classifiers=[
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Science/Research",
        "License :: OSI Approved :: MIT License",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
    ],
    entry_points={
        "console_scripts": [
            "arc-synthesize=arc_synthesis_framework.main:main",
        ],
    },
)
"""

# =====================================================================
# 3. README.md
# =====================================================================
README_MD = """# ARCç¨‹åºåˆæˆæ¡†æ¶

åŸºäºPopperçš„å½’çº³é€»è¾‘ç¼–ç¨‹ç³»ç»Ÿï¼Œç”¨äºè§£å†³ARCï¼ˆæŠ½è±¡ä¸æ¨ç†è¯­æ–™åº“ï¼‰ä»»åŠ¡ã€‚

## ç‰¹æ€§

- **Popper ILPé›†æˆ**: ä½¿ç”¨å½’çº³é€»è¾‘ç¼–ç¨‹è¿›è¡Œç¨‹åºåˆæˆ
- **å¯¹è±¡æå–**: ä»2Dç½‘æ ¼ä¸­æå–è¿é€šå¯¹è±¡åŠå…¶å±æ€§
- **CEGIS**: åä¾‹å¼•å¯¼çš„å½’çº³åˆæˆå¾ªç¯
- **åç»Ÿä¸€**: æ¨¡å¼æ³›åŒ–å’Œè§„åˆ™å‘ç°
- **ç©ºé—´æ¨ç†**: å®Œæ•´çš„ç©ºé—´å…³ç³»å¤„ç†
- **å¯æ‰©å±•æ¶æ„**: æ¨¡å—åŒ–è®¾è®¡æ”¯æŒæ–°è½¬æ¢ç±»å‹

## å®‰è£…

### å‰ç½®è¦æ±‚

1. Python 3.8+
2. SWI-Prolog
3. Clingo (ç”¨äºASPæ±‚è§£)

### å®‰è£…æ­¥éª¤

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/arc-team/synthesis-framework.git
cd synthesis-framework

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£…åŒ…
python setup.py install

# æˆ–å¼€å‘æ¨¡å¼å®‰è£…
pip install -e .
```

### Popperå®‰è£…

```bash
# å…‹éš†Popperä»“åº“
git clone https://github.com/logic-and-learning-lab/Popper.git
cd Popper
# æŒ‰ç…§Popperçš„å®‰è£…è¯´æ˜è¿›è¡Œå®‰è£…
```

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
from arc_synthesis_framework import ARCSynthesisEngine, SynthesisTask
from arc_synthesis_framework.utils.arc_loader import ARCDataLoader

# åˆå§‹åŒ–å¼•æ“
engine = ARCSynthesisEngine("config/default.yaml")

# åˆ›å»ºæˆ–åŠ è½½ARCä»»åŠ¡
loader = ARCDataLoader()
task = loader.create_simple_task()

# è¿è¡Œåˆæˆ
result = engine.synthesize_program(task)

if result.success:
    print(f"åˆæˆæˆåŠŸ: {result.program}")
    print(f"ç½®ä¿¡åº¦: {result.confidence:.2f}")
else:
    print(f"åˆæˆå¤±è´¥: {result.error_message}")
```

### å‘½ä»¤è¡Œä½¿ç”¨

```bash
# è¿è¡Œæ¼”ç¤º
python main.py --demo

# è¿è¡Œç‰¹å®šä»»åŠ¡
python main.py --task simple_color_change

# ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡
python main.py --task_file examples/simple_tasks/color_change.json

# è¿è¡Œæµ‹è¯•
python main.py --test
```

## é¡¹ç›®ç»“æ„

- `core/`: æ ¸å¿ƒåˆæˆå¼•æ“å’Œæ¥å£
- `extraction/`: å¯¹è±¡æå–å’Œç©ºé—´åˆ†æ
- `cegis/`: åä¾‹å¼•å¯¼åˆæˆå®ç°
- `utils/`: å·¥å…·å‡½æ•°å’Œæ•°æ®åŠ è½½
- `popper_files/`: Popperç›¸å…³æ–‡ä»¶å’Œæ¨¡æ¿
- `examples/`: ç¤ºä¾‹ä»»åŠ¡å’Œæ¼”ç¤ºä»£ç 
- `tests/`: å•å…ƒæµ‹è¯•

## é…ç½®

ä¸»è¦é…ç½®æ–‡ä»¶ä½äº `config/` ç›®å½•ï¼š

- `default.yaml`: åŸºæœ¬é…ç½®
- `spatial.yaml`: ç©ºé—´æ¨ç†ä»»åŠ¡é…ç½®
- `complex.yaml`: å¤æ‚ä»»åŠ¡é…ç½®

## æ‰©å±•æŒ‡å—

### æ·»åŠ æ–°çš„è½¬æ¢ç±»å‹

1. åœ¨ `extraction/transformations.py` ä¸­æ·»åŠ è½¬æ¢åˆ†æ
2. åœ¨ `popper_files/background/` ä¸­æ·»åŠ ç›¸å…³è°“è¯
3. æ›´æ–°åç½®æ–‡ä»¶ä»¥åŒ…å«æ–°çš„è°“è¯

### è‡ªå®šä¹‰å¯¹è±¡æ£€æµ‹

ç»§æ‰¿ `ARCObjectExtractor` ç±»å¹¶é‡å†™ç›¸å…³æ–¹æ³•ï¼š

```python
class CustomObjectExtractor(ARCObjectExtractor):
    def _classify_shape(self, cells, bbox):
        # è‡ªå®šä¹‰å½¢çŠ¶åˆ†ç±»é€»è¾‘
        pass
```

## è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºæ”¹è¿›å»ºè®®ã€‚

## è®¸å¯è¯

MIT License

## å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨æ­¤æ¡†æ¶ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{arc_synthesis_framework,
  title={ARC Program Synthesis Framework},
  author={ARC Research Team},
  year={2024},
  url={https://github.com/arc-team/synthesis-framework}
}
```
"""

# =====================================================================
# 4. config/default.yaml
# =====================================================================
CONFIG_DEFAULT_YAML = """# ARCç¨‹åºåˆæˆæ¡†æ¶é»˜è®¤é…ç½®

# Popperé…ç½®
popper:
  popper_path: "./popper"
  timeout: 300
  solver: "rc2"
  max_vars: 8
  max_body: 10
  max_rules: 5
  noisy: false
  enable_recursion: false

# å¯¹è±¡æå–é…ç½®
extraction:
  connectivity: 4  # 4è¿é€šæˆ–8è¿é€š
  min_object_size: 1
  background_color: 0
  analyze_shapes: true
  detect_patterns: true
  extract_holes: true

# CEGISé…ç½®
cegis:
  max_iterations: 25
  synthesis_timeout: 300
  verification_timeout: 60
  enable_parallel: false

# åç»Ÿä¸€é…ç½®
anti_unification:
  max_generalization_depth: 5
  preserve_structure: true
  enable_type_constraints: true
  min_pattern_support: 2

# éªŒè¯å™¨é…ç½®
oracle:
  validation_method: "exact_match"
  tolerance: 0.0
  enable_partial_credit: false

# æ—¥å¿—é…ç½®
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/synthesis.log"
  console_output: true

# æ€§èƒ½é…ç½®
performance:
  cache_enabled: true
  cache_size: 1000
  parallel_tasks: 1
  memory_limit_mb: 2048
"""

# =====================================================================
# 5. arc_synthesis_framework/__init__.py
# =====================================================================
MAIN_INIT_PY = '''"""
ARCç¨‹åºåˆæˆæ¡†æ¶ä¸»åŒ…

åŸºäºPopperçš„å½’çº³é€»è¾‘ç¼–ç¨‹ç³»ç»Ÿï¼Œç”¨äºè§£å†³ARCä»»åŠ¡ã€‚
"""

from .core.synthesis_engine import ARCSynthesisEngine, SynthesisTask, SynthesisResult
from .core.popper_interface import PopperInterface
from .extraction.object_extractor import ARCObjectExtractor, ARCObject
from .utils.arc_loader import ARCDataLoader

__version__ = "0.1.0"
__author__ = "ARC Research Team"
__email__ = "research@arc-synthesis.com"

__all__ = [
    "ARCSynthesisEngine", 
    "SynthesisTask", 
    "SynthesisResult",
    "PopperInterface",
    "ARCObjectExtractor", 
    "ARCObject",
    "ARCDataLoader"
]

# ç‰ˆæœ¬æ£€æŸ¥
import sys
if sys.version_info < (3, 8):
    raise RuntimeError("éœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")

# å¯é€‰çš„ä¾èµ–æ£€æŸ¥
def check_dependencies():
    """æ£€æŸ¥å…³é”®ä¾èµ–æ˜¯å¦å¯ç”¨"""
    missing_deps = []
    
    try:
        import numpy
    except ImportError:
        missing_deps.append("numpy")
    
    try:
        import yaml
    except ImportError:
        missing_deps.append("pyyaml")
    
    try:
        import sklearn
    except ImportError:
        missing_deps.append("scikit-learn")
    
    if missing_deps:
        raise ImportError(f"ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_deps)}")

# åœ¨å¯¼å…¥æ—¶è¿›è¡Œæ£€æŸ¥
check_dependencies()
'''

# =====================================================================
# 6. core/synthesis_engine.py (ä¸»åˆæˆå¼•æ“)
# =====================================================================
SYNTHESIS_ENGINE_PY = '''"""
ä¸»åˆæˆå¼•æ“ - ARCç¨‹åºåˆæˆçš„æ ¸å¿ƒ
"""
import logging
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass
from pathlib import Path
import json
import time
import yaml

from .popper_interface import PopperInterface
from .anti_unification import AntiUnifier
from .oracle import SolutionOracle
from ..extraction.object_extractor import ARCObjectExtractor
from ..cegis.synthesizer import CEGISSynthesizer
from ..cegis.verifier import ProgramVerifier
from ..cegis.counterexample import CounterexampleGenerator
from ..utils.arc_loader import ARCDataLoader
from ..utils.metrics import SynthesisMetrics
from ..utils.logging import setup_logging

logger = logging.getLogger(__name__)

@dataclass
class SynthesisTask:
    """è¡¨ç¤ºARCåˆæˆä»»åŠ¡"""
    task_id: str
    train_pairs: List[Tuple[List[List[int]], List[List[int]]]]
    test_pairs: List[Tuple[List[List[int]], List[List[int]]]]
    metadata: Dict[str, Any]
    
    @classmethod
    def from_file(cls, file_path: str) -> 'SynthesisTask':
        """ä»JSONæ–‡ä»¶åŠ è½½ä»»åŠ¡"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return cls(
            task_id=data.get('task_id', Path(file_path).stem),
            train_pairs=[(pair['input'], pair['output']) for pair in data['train']],
            test_pairs=[(pair['input'], pair['output']) for pair in data['test']],
            metadata=data.get('metadata', {})
        )
    
    def to_file(self, file_path: str):
        """ä¿å­˜ä»»åŠ¡åˆ°JSONæ–‡ä»¶"""
        data = {
            'task_id': self.task_id,
            'train': [{'input': inp, 'output': out} for inp, out in self.train_pairs],
            'test': [{'input': inp, 'output': out} for inp, out in self.test_pairs],
            'metadata': self.metadata
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

@dataclass
class SynthesisResult:
    """ç¨‹åºåˆæˆç»“æœ"""
    success: bool
    program: Optional[str]
    confidence: float
    synthesis_time: float
    iterations: int
    counterexamples_used: int
    generalization_pattern: Optional[str]
    error_message: Optional[str] = None
    intermediate_results: List[Dict] = None

class ARCSynthesisEngine:
    """
    ARCä¸»åˆæˆå¼•æ“
    
    é›†æˆPopper ILPã€CEGISã€å¯¹è±¡æå–å’Œåç»Ÿä¸€æŠ€æœ¯ï¼Œ
    å®ç°ç«¯åˆ°ç«¯çš„ARCä»»åŠ¡ç¨‹åºåˆæˆã€‚
    """
    
    def __init__(self, config_path: str = "config/default.yaml"):
        """
        åˆå§‹åŒ–åˆæˆå¼•æ“
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self._setup_logging()
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.popper = PopperInterface(self.config['popper'])
        self.object_extractor = ARCObjectExtractor(self.config['extraction'])
        self.cegis_synthesizer = CEGISSynthesizer(self.config['cegis'])
        self.verifier = ProgramVerifier(self.config.get('verification', {}))
        self.counterexample_gen = CounterexampleGenerator(self.config.get('counterexamples', {}))
        self.anti_unifier = AntiUnifier(self.config['anti_unification'])
        self.oracle = SolutionOracle(self.config['oracle'])
        self.metrics = SynthesisMetrics()
        
        # åˆæˆçŠ¶æ€ç®¡ç†
        self.synthesis_history = []
        self.learned_patterns = {}
        self.cached_results = {}
        
        logger.info("ARCåˆæˆå¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def synthesize_program(self, task: SynthesisTask) -> SynthesisResult:
        """
        ä¸»åˆæˆæ–¹æ³• - å®ç°å®Œæ•´çš„CEGISå¾ªç¯ä¸ILPé›†æˆ
        
        Args:
            task: ARCä»»åŠ¡è§„èŒƒ
            
        Returns:
            SynthesisResult: åŒ…å«ç¨‹åºå’Œå…ƒæ•°æ®çš„åˆæˆç»“æœ
        """
        start_time = time.time()
        logger.info(f"å¼€å§‹åˆæˆä»»åŠ¡ {task.task_id}")
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = self._generate_cache_key(task)
            if cache_key in self.cached_results:
                logger.info("ä½¿ç”¨ç¼“å­˜ç»“æœ")
                return self.cached_results[cache_key]
            
            # é˜¶æ®µ1: å¯¹è±¡æå–å’Œåˆ†æ
            logger.info("é˜¶æ®µ1: å¯¹è±¡æå–å’Œç©ºé—´åˆ†æ")
            extracted_objects = self._extract_objects_from_pairs(task.train_pairs)
            spatial_relations = self._analyze_spatial_relations(extracted_objects)
            
            # é˜¶æ®µ2: ç”ŸæˆPopperè¾“å…¥æ–‡ä»¶
            logger.info("é˜¶æ®µ2: ç”ŸæˆPopperå­¦ä¹ æ–‡ä»¶")
            popper_files = self._generate_popper_files(task, extracted_objects, spatial_relations)
            
            # é˜¶æ®µ3: CEGISåˆæˆå¾ªç¯
            logger.info("é˜¶æ®µ3: å¼€å§‹CEGISåˆæˆå¾ªç¯")
            result = self._cegis_synthesis_loop(task, popper_files)
            
            # é˜¶æ®µ4: åç»Ÿä¸€å’Œæ¨¡å¼æ³›åŒ–
            if result.success:
                logger.info("é˜¶æ®µ4: åº”ç”¨åç»Ÿä¸€è¿›è¡Œæ¨¡å¼æ³›åŒ–")
                generalized_pattern = self._generalize_solution(result.program, task)
                result.generalization_pattern = generalized_pattern
            
            # é˜¶æ®µ5: æœ€ç»ˆéªŒè¯å’Œæµ‹è¯•
            if result.success:
                logger.info("é˜¶æ®µ5: æœ€ç»ˆéªŒè¯")
                validation_result = self._validate_solution(result.program, task)
                result.success = validation_result
            
            # å®Œæˆè®¡æ—¶å’Œè®°å½•
            result.synthesis_time = time.time() - start_time
            self._log_synthesis_result(task, result)
            
            # ç¼“å­˜ç»“æœ
            if self.config.get('performance', {}).get('cache_enabled', True):
                self.cached_results[cache_key] = result
            
            return result
            
        except Exception as e:
            logger.error(f"ä»»åŠ¡ {task.task_id} åˆæˆå¤±è´¥: {str(e)}", exc_info=True)
            return SynthesisResult(
                success=False,
                program=None,
                confidence=0.0,
                synthesis_time=time.time() - start_time,
                iterations=0,
                counterexamples_used=0,
                generalization_pattern=None,
                error_message=str(e)
            )
    
    def _extract_objects_from_pairs(self, train_pairs: List[Tuple]) -> Dict:
        """ä»æ‰€æœ‰è®­ç»ƒå¯¹ä¸­æå–å¯¹è±¡å’Œè½¬æ¢æ¨¡å¼"""
        all_objects = {}
        
        for pair_idx, (input_grid, output_grid) in enumerate(train_pairs):
            logger.debug(f"å¤„ç†è®­ç»ƒå¯¹ {pair_idx + 1}")
            
            # æå–è¾“å…¥å’Œè¾“å‡ºå¯¹è±¡
            input_analysis = self.object_extractor.process_arc_grid(input_grid)
            output_analysis = self.object_extractor.process_arc_grid(output_grid)
            
            # åˆ†æè½¬æ¢æ¨¡å¼
            transformation = self.object_extractor.extract_transformation_pattern(
                input_grid, output_grid
            )
            
            all_objects[f"pair_{pair_idx}"] = {
                'input_analysis': input_analysis,
                'output_analysis': output_analysis,
                'transformation': transformation,
                'input_grid': input_grid,
                'output_grid': output_grid
            }
        
        return all_objects
    
    def _generate_popper_files(self, task: SynthesisTask, objects: Dict, relations: Dict) -> Dict:
        """ç”ŸæˆPopper ILPæ‰€éœ€çš„è¾“å…¥æ–‡ä»¶"""
        
        # åˆ›å»ºä»»åŠ¡ç›®å½•
        task_dir = Path(f"popper_files/tasks/{task.task_id}")
        task_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å†…å®¹
        examples_content = self._generate_examples_file(task, objects)
        bk_content = self._generate_background_knowledge(objects, relations)
        bias_content = self._generate_bias_file(task, objects)
        
        # å†™å…¥æ–‡ä»¶
        files = {
            'examples': task_dir / "exs.pl",
            'background': task_dir / "bk.pl", 
            'bias': task_dir / "bias.pl"
        }
        
        files['examples'].write_text(examples_content, encoding='utf-8')
        files['background'].write_text(bk_content, encoding='utf-8')
        files['bias'].write_text(bias_content, encoding='utf-8')
        
        logger.debug(f"ç”ŸæˆPopperæ–‡ä»¶åˆ° {task_dir}")
        return files
    
    def _generate_examples_file(self, task: SynthesisTask, objects: Dict) -> str:
        """ç”ŸæˆPopperç¤ºä¾‹æ–‡ä»¶ (exs.pl)"""
        examples = [
            f"% ARCä»»åŠ¡ {task.task_id} çš„è®­ç»ƒç¤ºä¾‹",
            f"% ä»»åŠ¡æè¿°: {task.metadata.get('description', 'æœªçŸ¥')}",
            ""
        ]
        
        for pair_idx, (input_grid, output_grid) in enumerate(task.train_pairs):
            # å°†ç½‘æ ¼è½¬æ¢ä¸ºç»“æ„åŒ–è¡¨ç¤º
            input_facts = self._grid_to_facts(input_grid, f"input_{pair_idx}")
            output_facts = self._grid_to_facts(output_grid, f"output_{pair_idx}")
            
            # åˆ›å»ºæ­£ä¾‹
            examples.append(f"pos(transform({input_facts}, {output_facts})).")
        
        # æ·»åŠ è´Ÿä¾‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
        examples.extend(self._generate_negative_examples(task, objects))
        
        return "\\n".join(examples)
    
    def _grid_to_facts(self, grid: List[List[int]], grid_name: str) -> str:
        """å°†ç½‘æ ¼è½¬æ¢ä¸ºPrologäº‹å®è¡¨ç¤º"""
        facts = []
        for r_idx, row in enumerate(grid):
            for c_idx, cell_value in enumerate(row):
                facts.append(f"cell({r_idx},{c_idx},{cell_value})")
        
        return f"grid([{','.join(facts)}])"
    
    def _generate_background_knowledge(self, objects: Dict, relations: Dict) -> str:
        """ç”ŸæˆèƒŒæ™¯çŸ¥è¯†æ–‡ä»¶ (bk.pl)"""
        bk_lines = [
            f"% ARCä»»åŠ¡èƒŒæ™¯çŸ¥è¯† - è‡ªåŠ¨ç”Ÿæˆ",
            f"% ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "% ===== åŸºç¡€ç½‘æ ¼æ“ä½œ =====",
            "",
            "% è·å–ç½‘æ ¼å°ºå¯¸",
            "grid_size(grid(Cells), Width, Height) :-",
            "    findall(X, member(cell(_, X, _), Cells), Xs),",
            "    findall(Y, member(cell(Y, _, _), Cells), Ys),",
            "    (Xs = [] -> Width = 0; (max_list(Xs, MaxX), Width is MaxX + 1)),",
            "    (Ys = [] -> Height = 0; (max_list(Ys, MaxY), Height is MaxY + 1)).",
            "",
            "% è·å–ç‰¹å®šä½ç½®çš„é¢œè‰²",
            "cell_color(grid(Cells), R, C, Color) :-",
            "    member(cell(R, C, Color), Cells).",
            "",
            "% è¾¹ç•Œæ£€æŸ¥",
            "in_bounds(X, Y, Grid) :-",
            "    grid_size(Grid, W, H),",
            "    X >= 0, X < W, Y >= 0, Y < H.",
            "",
            "% ===== é¢œè‰²è½¬æ¢æ“ä½œ =====",
            "",
            "% å…¨å±€é¢œè‰²æ›¿æ¢",
            "change_all_color(grid(Cells), OldColor, NewColor, grid(NewCells)) :-",
            "    maplist(replace_color(OldColor, NewColor), Cells, NewCells).",
            "",
            "replace_color(OldColor, NewColor, cell(R,C,OldColor), cell(R,C,NewColor)) :- !.",
            "replace_color(_, _, Cell, Cell).",
            "",
            "% ===== ç©ºé—´å…³ç³»è°“è¯ =====",
            "",
            "% 4è¿é€šç›¸é‚»",
            "adjacent_4(cell(R1,C1,_), cell(R2,C2,_)) :-",
            "    (R1 =:= R2, abs(C1-C2) =:= 1);",
            "    (C1 =:= C2, abs(R1-R2) =:= 1).",
            "",
            "% 8è¿é€šç›¸é‚»", 
            "adjacent_8(cell(R1,C1,_), cell(R2,C2,_)) :-",
            "    abs(R1-R2) =< 1, abs(C1-C2) =< 1,",
            "    \\+ (R1 =:= R2, C1 =:= C2).",
            "",
            "% ===== å¯¹è±¡æ£€æµ‹å’Œåˆ†æ =====",
            "",
            "% æ£€æµ‹æ‰€æœ‰å¯¹è±¡",
            "detect_objects(Grid, Objects) :-",
            "    findall(Color-Cells, detect_color_group(Grid, Color, Cells), Groups),",
            "    include(non_empty_group, Groups, Objects).",
            "",
            "detect_color_group(grid(Cells), Color, ColorCells) :-",
            "    include(has_color(Color), Cells, ColorCells),",
            "    Color \\= 0.  % æ’é™¤èƒŒæ™¯è‰²",
            "",
            "has_color(Color, cell(_,_,Color)).",
            "non_empty_group(_-Cells) :- Cells \\= [].",
            "",
            "% ===== æ¨¡å¼åŒ¹é… =====",
            "",
            "% æ£€æµ‹ç›´çº¿æ¨¡å¼",
            "is_line(Cells) :-",
            "    length(Cells, Len), Len > 1,",
            "    (all_same_row(Cells); all_same_col(Cells)).",
            "",
            "all_same_row([cell(R,_,_)|Rest]) :-",
            "    maplist(same_row(R), Rest).",
            "same_row(R, cell(R,_,_)).",
            "",
            "all_same_col([cell(_,C,_)|Rest]) :-",
            "    maplist(same_col(C), Rest).",
            "same_col(C, cell(_,C,_)).",
            ""
        ]
        
        # æ·»åŠ ä»»åŠ¡ç‰¹å®šçš„èƒŒæ™¯çŸ¥è¯†
        task_specific_bk = self._generate_task_specific_background(objects)
        bk_lines.extend(task_specific_bk)
        
        return "\\n".join(bk_lines)
    
    def _generate_bias_file(self, task: SynthesisTask, objects: Dict) -> str:
        """ç”Ÿæˆåç½®æ–‡ä»¶ (bias.pl)"""
        bias_lines = [
            f"% ARCä»»åŠ¡ {task.task_id} çš„å­¦ä¹ åç½®",
            f"% ä»»åŠ¡ç±»å‹: {task.metadata.get('type', 'unknown')}",
            "",
            "% ===== å¤´è°“è¯å®šä¹‰ =====",
            "head_pred(transform,2).",
            "",
            "% ===== ä½“è°“è¯å®šä¹‰ =====",
            "",
            "% åŸºç¡€ç½‘æ ¼æ“ä½œ",
            "body_pred(grid,1).",
            "body_pred(cell,3).",
            "body_pred(cell_color,4).",
            "body_pred(grid_size,3).",
            "",
            "% é¢œè‰²æ“ä½œ",
            "body_pred(change_all_color,4).",
            "body_pred(replace_color,4).",
            "",
            "% ç©ºé—´å…³ç³»",
            "body_pred(adjacent_4,2).",
            "body_pred(adjacent_8,2).",
            "",
            "% å¯¹è±¡æ£€æµ‹",
            "body_pred(detect_objects,2).",
            "body_pred(is_line,1).",
            "",
            "% ===== ç±»å‹çº¦æŸ =====",
            "",
            "type(transform,(grid,grid)).",
            "type(cell,(int,int,int)).",
            "type(change_all_color,(grid,int,int,grid)).",
            "type(grid_size,(grid,int,int)).",
            "",
            "% ===== æ–¹å‘çº¦æŸ =====",
            "",
            "direction(transform,(in,out)).",
            "direction(change_all_color,(in,in,in,out)).",
            "",
            "% ===== å­¦ä¹ æ§åˆ¶å‚æ•° =====",
            "",
            f"max_vars({self.config['popper'].get('max_vars', 8)}).",
            f"max_body({self.config['popper'].get('max_body', 10)}).",
            f"max_rules({self.config['popper'].get('max_rules', 5)}).",
            "",
            "% å…è®¸å•ä¾‹å˜é‡ï¼ˆå¯¹ARCä»»åŠ¡æœ‰ç”¨ï¼‰",
            "allow_singletons.",
            ""
        ]
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹æ·»åŠ ç‰¹å®šåç½®
        task_type = task.metadata.get('type', 'unknown')
        if task_type == 'color_transformation':
            bias_lines.extend([
                "% é¢œè‰²è½¬æ¢ä»»åŠ¡ç‰¹å®šåç½®",
                "body_pred(same_color,2).",
                "body_pred(different_color,2)."
            ])
        elif task_type == 'spatial_transformation':
            bias_lines.extend([
                "% ç©ºé—´è½¬æ¢ä»»åŠ¡ç‰¹å®šåç½®", 
                "body_pred(translate,4).",
                "body_pred(rotate,3).",
                "body_pred(reflect,2)."
            ])
        
        return "\\n".join(bias_lines)
    
    def _cegis_synthesis_loop(self, task: SynthesisTask, popper_files: Dict) -> SynthesisResult:
        """å®ç°CEGISåˆæˆå¾ªç¯"""
        counterexamples = []
        iteration = 0
        max_iterations = self.config['cegis']['max_iterations']
        
        logger.info(f"å¼€å§‹CEGISå¾ªç¯ï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
        
        while iteration < max_iterations:
            logger.info(f"CEGISè¿­ä»£ {iteration + 1}/{max_iterations}")
            
            # ä½¿ç”¨Popperç”Ÿæˆå€™é€‰ç¨‹åº
            candidate = self._generate_candidate_with_popper(
                popper_files, counterexamples, iteration
            )
            
            if candidate is None:
                logger.info("æ— æ³•ç”Ÿæˆæ›´å¤šå€™é€‰ç¨‹åº - æœç´¢ç©ºé—´å·²ç©·å°½")
                return SynthesisResult(
                    success=False, program=None, confidence=0.0,
                    synthesis_time=0, iterations=iteration,
                    counterexamples_used=len(counterexamples),
                    generalization_pattern=None,
                    error_message="æœç´¢ç©ºé—´å·²ç©·å°½"
                )
            
            logger.debug(f"ç”Ÿæˆå€™é€‰ç¨‹åº: {candidate}")
            
            # éªŒè¯å€™é€‰ç¨‹åº
            verification_result = self.verifier.verify_candidate(candidate, task.train_pairs)
            
            if verification_result.is_valid:
                logger.info(f"åœ¨è¿­ä»£ {iteration + 1} ä¸­æ‰¾åˆ°æœ‰æ•ˆç¨‹åº")
                confidence = self._calculate_confidence(candidate, task)
                return SynthesisResult(
                    success=True, program=candidate, confidence=confidence,
                    synthesis_time=0, iterations=iteration + 1,
                    counterexamples_used=len(counterexamples),
                    generalization_pattern=None
                )
            else:
                # ç”Ÿæˆåä¾‹çº¦æŸ
                new_counterexample = self.counterexample_gen.generate(
                    candidate, verification_result.failed_example
                )
                counterexamples.append(new_counterexample)
                logger.info(f"æ·»åŠ åä¾‹çº¦æŸ {len(counterexamples)}: {new_counterexample}")
            
            iteration += 1
        
        logger.warning("CEGISè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œåˆæˆå¤±è´¥")
        return SynthesisResult(
            success=False, program=None, confidence=0.0,
            synthesis_time=0, iterations=max_iterations,
            counterexamples_used=len(counterexamples),
            generalization_pattern=None,
            error_message="è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°"
        )
    
    def _generate_candidate_with_popper(self, popper_files: Dict, 
                                      counterexamples: List[str], 
                                      iteration: int) -> Optional[str]:
        """ä½¿ç”¨Popperç”Ÿæˆå€™é€‰ç¨‹åº"""
        logger.debug(f"è°ƒç”¨Popperç”Ÿæˆå€™é€‰ç¨‹åºï¼Œåä¾‹æ•°é‡: {len(counterexamples)}")
        
        # å‡†å¤‡çº¦æŸï¼ˆå¦‚æœæœ‰åä¾‹ï¼‰
        constraints = []
        if counterexamples:
            constraints.append(f"% è¿­ä»£ {iteration} çš„çº¦æŸ")
            constraints.extend(counterexamples)
        
        # è°ƒç”¨Popper
        task_dir = popper_files['examples'].parent
        program = self.popper.learn_program(task_dir, constraints if counterexamples else None)
        
        return program
    
    def _calculate_confidence(self, candidate: str, task: SynthesisTask) -> float:
        """è®¡ç®—å€™é€‰ç¨‹åºçš„ç½®ä¿¡åº¦"""
        # åŸºäºå¤šä¸ªå› ç´ è®¡ç®—ç½®ä¿¡åº¦ï¼š
        # 1. ç¨‹åºå¤æ‚åº¦ï¼ˆè¶Šç®€å•è¶Šå¥½ï¼‰
        # 2. è®­ç»ƒå‡†ç¡®ç‡
        # 3. æ³›åŒ–èƒ½åŠ›è¯„ä¼°
        
        try:
            # ç¨‹åºå¤æ‚åº¦åˆ†æ•°ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰
            complexity_score = self._calculate_complexity_score(candidate)
            
            # è®­ç»ƒå‡†ç¡®ç‡ï¼ˆè¿™é‡Œåº”è¯¥æ˜¯1.0ï¼Œå› ä¸ºå·²ç»éªŒè¯é€šè¿‡ï¼‰
            training_accuracy = 1.0
            
            # ç»¼åˆè®¡ç®—
            confidence = 0.6 * training_accuracy + 0.4 * complexity_score
            
            return min(1.0, max(0.0, confidence))
            
        except Exception as e:
            logger.warning(f"è®¡ç®—ç½®ä¿¡åº¦æ—¶å‡ºé”™: {str(e)}")
            return 0.5  # é»˜è®¤ä¸­ç­‰ç½®ä¿¡åº¦
    
    def _calculate_complexity_score(self, program: str) -> float:
        """è®¡ç®—ç¨‹åºå¤æ‚åº¦åˆ†æ•°"""
        if not program:
            return 0.0
        
        lines = [line.strip() for line in program.split('\\n') if line.strip()]
        
        # ç®€å•çš„å¤æ‚åº¦åº¦é‡
        rule_count = len(lines)
        avg_rule_length = sum(len(line) for line in lines) / max(1, rule_count)
        
        # å½’ä¸€åŒ–åˆ†æ•°ï¼ˆæ›´å°‘çš„è§„åˆ™å’Œæ›´çŸ­çš„è§„åˆ™å¾—åˆ†æ›´é«˜ï¼‰
        rule_score = max(0, 1 - (rule_count - 1) / 10)  # 1-10è§„åˆ™
        length_score = max(0, 1 - (avg_rule_length - 20) / 100)  # 20-120å­—ç¬¦
        
        return (rule_score + length_score) / 2
    
    # è¾…åŠ©æ–¹æ³•
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            logger.warning(f"é…ç½®æ–‡ä»¶ {config_path} æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'popper': {'popper_path': './popper', 'timeout': 300, 'max_vars': 8},
            'extraction': {'connectivity': 4, 'min_object_size': 1},
            'cegis': {'max_iterations': 25},
            'anti_unification': {'max_generalization_depth': 5},
            'oracle': {'validation_method': 'exact_match'}
        }
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_config = self.config.get('logging', {})
        setup_logging(
            level=log_config.get('level', 'INFO'),
            format_str=log_config.get('format'),
            log_file=log_config.get('file')
        )
    
    # å…¶ä»–è¾…åŠ©æ–¹æ³•...
    def _analyze_spatial_relations(self, objects: Dict) -> Dict:
        """åˆ†æç©ºé—´å…³ç³»ï¼ˆå¾…å®ç°ï¼‰"""
        return {'relations': []}
    
    def _generate_negative_examples(self, task: SynthesisTask, objects: Dict) -> List[str]:
        """ç”Ÿæˆè´Ÿä¾‹ï¼ˆå¯é€‰ï¼‰"""
        return ["% æš‚æ— è´Ÿä¾‹"]
    
    def _generate_task_specific_background(self, objects: Dict) -> List[str]:
        """ç”Ÿæˆä»»åŠ¡ç‰¹å®šèƒŒæ™¯çŸ¥è¯†"""
        return ["% ä»»åŠ¡ç‰¹å®šèƒŒæ™¯çŸ¥è¯†å¾…æ·»åŠ "]
    
    def _generalize_solution(self, program: str, task: SynthesisTask) -> str:
        """æ³›åŒ–è§£å†³æ–¹æ¡ˆ"""
        return self.anti_unifier.generalize_program(program, task.train_pairs)
    
    def _validate_solution(self, program: str, task: SynthesisTask) -> bool:
        """éªŒè¯è§£å†³æ–¹æ¡ˆ"""
        return self.oracle.validate_program(program, task.test_pairs)
    
    def _generate_cache_key(self, task: SynthesisTask) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"{task.task_id}_{hash(str(task.train_pairs))}"
    
    def _log_synthesis_result(self, task: SynthesisTask, result: SynthesisResult):
        """è®°å½•åˆæˆç»“æœ"""
        if result.success:
            logger.info(f"âœ“ ä»»åŠ¡ {task.task_id} åˆæˆæˆåŠŸ")
            logger.info(f"  ç¨‹åº: {result.program}")
            logger.info(f"  ç½®ä¿¡åº¦: {result.confidence:.2f}")
            logger.info(f"  è¿­ä»£: {result.iterations}, æ—¶é—´: {result.synthesis_time:.2f}s")
        else:
            logger.warning(f"âœ— ä»»åŠ¡ {task.task_id} åˆæˆå¤±è´¥: {result.error_message}")
'''

# =====================================================================
# 7. main.py (ä¸»è¿è¡Œæ–‡ä»¶)
# =====================================================================
MAIN_PY = '''#!/usr/bin/env python3
"""
ARCç¨‹åºåˆæˆæ¡†æ¶ä¸»è¿è¡Œæ–‡ä»¶
"""
import argparse
import sys
import logging
from pathlib import Path

# ç¡®ä¿å¯ä»¥å¯¼å…¥æœ¬åœ°åŒ…
sys.path.insert(0, str(Path(__file__).parent))

from arc_synthesis_framework import ARCSynthesisEngine, SynthesisTask
from arc_synthesis_framework.utils.arc_loader import ARCDataLoader
from arc_synthesis_framework.utils.metrics import SynthesisMetrics

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ARCç¨‹åºåˆæˆæ¡†æ¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  %(prog)s --demo                    # è¿è¡Œæ¼”ç¤º
  %(prog)s --task simple_task        # è¿è¡Œç‰¹å®šä»»åŠ¡
  %(prog)s --task_file task.json     # ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡
  %(prog)s --test                    # è¿è¡Œæµ‹è¯•
        """
    )
    
    parser.add_argument("--config", default="config/default.yaml", 
                       help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config/default.yaml)")
    parser.add_argument("--task", help="ç‰¹å®šä»»åŠ¡ID")
    parser.add_argument("--task_file", help="ä»»åŠ¡æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--demo", action="store_true", 
                       help="è¿è¡Œæ¼”ç¤ºä»»åŠ¡")
    parser.add_argument("--test", action="store_true", 
                       help="è¿è¡Œå•å…ƒæµ‹è¯•")
    parser.add_argument("--batch", help="æ‰¹é‡å¤„ç†ä»»åŠ¡ç›®å½•")
    parser.add_argument("--output", help="ç»“æœè¾“å‡ºæ–‡ä»¶")
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.basicConfig(level=logging.DEBUG)
    
    try:
        if args.demo:
            run_demo(args.config)
        elif args.test:
            run_tests()
        elif args.batch:
            run_batch_tasks(args.batch, args.config, args.output)
        elif args.task_file:
            run_single_task_from_file(args.task_file, args.config)
        elif args.task:
            run_single_task(args.task, args.config)
        else:
            print("è¯·æŒ‡å®šè¿è¡Œæ¨¡å¼ã€‚ä½¿ç”¨ --help æŸ¥çœ‹é€‰é¡¹ã€‚")
            parser.print_help()
            return 1
    
    except KeyboardInterrupt:
        print("\\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        print(f"é”™è¯¯: {str(e)}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1
    
    return 0

def run_demo(config_path: str = "config/default.yaml"):
    """è¿è¡Œæ¼”ç¤º"""
    print("=" * 60)
    print("ğŸ§  ARCç¨‹åºåˆæˆæ¡†æ¶æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–ç»„ä»¶
        print("\\nğŸ“¦ åˆå§‹åŒ–åˆæˆå¼•æ“...")
        engine = ARCSynthesisEngine(config_path)
        loader = ARCDataLoader()
        metrics = SynthesisMetrics()
        
        # åˆ›å»ºç®€å•æµ‹è¯•ä»»åŠ¡
        print("\\nğŸ¯ åˆ›å»ºæ¼”ç¤ºä»»åŠ¡...")
        task = loader.create_simple_task()
        
        print(f"ä»»åŠ¡ID: {task.task_id}")
        print(f"æè¿°: {task.metadata.get('description', 'ç®€å•é¢œè‰²è½¬æ¢')}")
        print(f"è®­ç»ƒæ ·ä¾‹: {len(task.train_pairs)} ä¸ª")
        print(f"æµ‹è¯•æ ·ä¾‹: {len(task.test_pairs)} ä¸ª")
        
        # æ˜¾ç¤ºæ ·ä¾‹
        print("\\nğŸ“Š è®­ç»ƒæ ·ä¾‹:")
        for i, (inp, out) in enumerate(task.train_pairs):
            print(f"  æ ·ä¾‹ {i+1}:")
            print(f"    è¾“å…¥:  {inp}")
            print(f"    è¾“å‡º:  {out}")
        
        # æ‰§è¡Œåˆæˆ
        print("\\nğŸ”„ å¼€å§‹ç¨‹åºåˆæˆ...")
        print("-" * 40)
        
        result = engine.synthesize_program(task)
        
        # è®°å½•æŒ‡æ ‡
        metrics.add_task_result(
            task.task_id, result.success, result.synthesis_time,
            result.iterations, result.program or "", result.confidence
        )
        
        # æ˜¾ç¤ºç»“æœ
        print("\\nğŸ“‹ åˆæˆç»“æœ:")
        print("-" * 40)
        
        if result.success:
            print("âœ… åˆæˆæˆåŠŸ!")
            print(f"ğŸ“ ç¨‹åº:")
            for line in (result.program or "").split('\\n'):
                if line.strip():
                    print(f"    {line}")
            print(f"ğŸ¯ ç½®ä¿¡åº¦: {result.confidence:.2%}")
            print(f"ğŸ”„ è¿­ä»£æ¬¡æ•°: {result.iterations}")
            print(f"â±ï¸  åˆæˆæ—¶é—´: {result.synthesis_time:.2f}ç§’")
            
            if result.generalization_pattern:
                print(f"ğŸ” æ³›åŒ–æ¨¡å¼: {result.generalization_pattern}")
        else:
            print("âŒ åˆæˆå¤±è´¥")
            print(f"ğŸ’¥ é”™è¯¯ä¿¡æ¯: {result.error_message}")
            print(f"ğŸ”„ å°è¯•è¿­ä»£: {result.iterations}")
            print(f"â±ï¸  ç”¨æ—¶: {result.synthesis_time:.2f}ç§’")
        
        # æ˜¾ç¤ºç»Ÿè®¡
        print("\\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
        print("-" * 40)
        metrics.print_summary()
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿è¡Œå¤±è´¥: {str(e)}")
        raise

def run_single_task_from_file(task_file: str, config_path: str):
    """ä»æ–‡ä»¶è¿è¡Œå•ä¸ªä»»åŠ¡"""
    print(f"ğŸ”„ ä»æ–‡ä»¶åŠ è½½ä»»åŠ¡: {task_file}")
    
    try:
        engine = ARCSynthesisEngine(config_path)
        task = SynthesisTask.from_file(task_file)
        
        print(f"âœ… æˆåŠŸåŠ è½½ä»»åŠ¡: {task.task_id}")
        print(f"ğŸ“Š è®­ç»ƒæ ·ä¾‹: {len(task.train_pairs)}")
        print(f"ğŸ§ª æµ‹è¯•æ ·ä¾‹: {len(task.test_pairs)}")
        
        result = engine.synthesize_program(task)
        
        print("\\nğŸ“‹ ç»“æœ:")
        if result.success:
            print("âœ… åˆæˆæˆåŠŸ")
            print(f"ğŸ“ ç¨‹åº: {result.program}")
            print(f"ğŸ¯ ç½®ä¿¡åº¦: {result.confidence:.2%}")
        else:
            print("âŒ åˆæˆå¤±è´¥")
            print(f"ğŸ’¥ é”™è¯¯: {result.error_message}")
            
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {task_file}")
    except Exception as e:
        print(f"âŒ è¿è¡Œå¤±è´¥: {str(e)}")

def run_single_task(task_id: str, config_path: str):
    """è¿è¡Œå•ä¸ªæŒ‡å®šä»»åŠ¡"""
    print(f"ğŸ”„ è¿è¡Œä»»åŠ¡: {task_id}")
    
    try:
        engine = ARCSynthesisEngine(config_path)
        loader = ARCDataLoader()
        
        task = loader.load_task(task_id)
        result = engine.synthesize_program(task)
        
        print("\\nğŸ“‹ ç»“æœ:")
        if result.success:
            print("âœ… åˆæˆæˆåŠŸ")
            print(f"ğŸ“ ç¨‹åº: {result.program}")
        else:
            print("âŒ åˆæˆå¤±è´¥") 
            print(f"ğŸ’¥ é”™è¯¯: {result.error_message}")
            
    except FileNotFoundError:
        print(f"âŒ ä»»åŠ¡ {task_id} æœªæ‰¾åˆ°")
    except Exception as e:
        print(f"âŒ è¿è¡Œå¤±è´¥: {str(e)}")

def run_batch_tasks(task_dir: str, config_path: str, output_file: str = None):
    """æ‰¹é‡è¿è¡Œä»»åŠ¡"""
    print(f"ğŸ”„ æ‰¹é‡å¤„ç†ä»»åŠ¡ç›®å½•: {task_dir}")
    
    try:
        engine = ARCSynthesisEngine(config_path)
        metrics = SynthesisMetrics()
        
        # æŸ¥æ‰¾æ‰€æœ‰ä»»åŠ¡æ–‡ä»¶
        task_path = Path(task_dir)
        task_files = list(task_path.glob("*.json"))
        
        if not task_files:
            print(f"âŒ åœ¨ç›®å½• {task_dir} ä¸­æœªæ‰¾åˆ°ä»»åŠ¡æ–‡ä»¶")
            return
        
        print(f"ğŸ“ æ‰¾åˆ° {len(task_files)} ä¸ªä»»åŠ¡æ–‡ä»¶")
        
        results = []
        
        for i, task_file in enumerate(task_files, 1):
            print(f"\\n[{i}/{len(task_files)}] å¤„ç† {task_file.name}")
            
            try:
                task = SynthesisTask.from_file(str(task_file))
                result = engine.synthesize_program(task)
                
                metrics.add_task_result(
                    task.task_id, result.success, result.synthesis_time,
                    result.iterations, result.program or "", result.confidence
                )
                
                results.append({
                    'task_id': task.task_id,
                    'file': task_file.name,
                    'success': result.success,
                    'program': result.program,
                    'confidence': result.confidence,
                    'time': result.synthesis_time,
                    'error': result.error_message
                })
                
                status = "âœ…" if result.success else "âŒ"
                print(f"  {status} {task.task_id}: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}")
                
            except Exception as e:
                print(f"  âŒ {task_file.name}: å¤„ç†å¤±è´¥ - {str(e)}")
                results.append({
                    'task_id': task_file.stem,
                    'file': task_file.name,
                    'success': False,
                    'error': str(e)
                })
        
        # æ˜¾ç¤ºæ€»ç»“
        print("\\n" + "="*60)
        print("ğŸ“ˆ æ‰¹é‡å¤„ç†ç»“æœæ€»ç»“")
        print("="*60)
        metrics.print_summary()
        
        # ä¿å­˜ç»“æœ
        if output_file:
            save_batch_results(results, output_file)
            print(f"\\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")

def save_batch_results(results: list, output_file: str):
    """ä¿å­˜æ‰¹é‡å¤„ç†ç»“æœ"""
    import json
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

def run_tests():
    """è¿è¡Œå•å…ƒæµ‹è¯•"""
    print("ğŸ§ª è¿è¡Œå•å…ƒæµ‹è¯•...")
    
    try:
        import unittest
        
        # å‘ç°å¹¶è¿è¡Œæµ‹è¯•
        loader = unittest.TestLoader()
        suite = loader.discover('tests', pattern='test_*.py')
        
        if suite.countTestCases() == 0:
            print("âš ï¸  æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶")
            print("è¯·ç¡®ä¿æµ‹è¯•æ–‡ä»¶ä½äº 'tests/' ç›®å½•ä¸­")
            return
        
        print(f"ğŸ“ æ‰¾åˆ° {suite.countTestCases()} ä¸ªæµ‹è¯•")
        
        runner = unittest.TextTestRunner(
            verbosity=2,
            descriptions=True,
            failfast=False
        )
        
        result = runner.run(suite)
        
        if result.wasSuccessful():
            print("\\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        else:
            print(f"\\nâŒ {len(result.failures)} ä¸ªæµ‹è¯•å¤±è´¥, {len(result.errors)} ä¸ªé”™è¯¯")
            return 1
            
    except ImportError as e:
        print(f"âŒ å¯¼å…¥æµ‹è¯•æ¨¡å—å¤±è´¥: {str(e)}")
        print("è¯·ç¡®ä¿å·²å®‰è£… unittest æˆ– pytest")
        return 1

if __name__ == "__main__":
    sys.exit(main())
'''

# =====================================================================
# è¯´æ˜ï¼šå®Œæ•´æ–‡ä»¶æ¸…å•
# =====================================================================
FILE_LIST = """
å®Œæ•´é¡¹ç›®æ–‡ä»¶æ¸…å•:

1. æ ¹ç›®å½•æ–‡ä»¶:
   - requirements.txt          # Pythonä¾èµ–
   - setup.py                  # åŒ…å®‰è£…é…ç½®
   - README.md                 # é¡¹ç›®è¯´æ˜
   - main.py                   # ä¸»è¿è¡Œæ–‡ä»¶

2. é…ç½®æ–‡ä»¶ (config/):
   - default.yaml              # é»˜è®¤é…ç½®
   - spatial.yaml              # ç©ºé—´æ¨ç†é…ç½® 
   - complex.yaml              # å¤æ‚ä»»åŠ¡é…ç½®

3. æ ¸å¿ƒæ¨¡å— (arc_synthesis_framework/core/):
   - __init__.py               # æ ¸å¿ƒæ¨¡å—åˆå§‹åŒ–
   - synthesis_engine.py       # ä¸»åˆæˆå¼•æ“(å·²åŒ…å«)
   - popper_interface.py       # Popperæ¥å£
   - anti_unification.py       # åç»Ÿä¸€ç®—æ³•
   - oracle.py                 # è§£å†³æ–¹æ¡ˆéªŒè¯

4. æå–æ¨¡å— (arc_synthesis_framework/extraction/):
   - __init__.py               # æå–æ¨¡å—åˆå§‹åŒ–
   - object_extractor.py       # å¯¹è±¡æå–å™¨(æ ¸å¿ƒæ–‡ä»¶å·²åŒ…å«)
   - spatial_predicates.py     # ç©ºé—´è°“è¯ç”Ÿæˆ
   - transformations.py        # è½¬æ¢åˆ†æ

5. CEGISæ¨¡å— (arc_synthesis_framework/cegis/):
   - __init__.py               # CEGISæ¨¡å—åˆå§‹åŒ–
   - synthesizer.py            # CEGISåˆæˆå™¨
   - verifier.py               # ç¨‹åºéªŒè¯å™¨
   - counterexample.py         # åä¾‹ç”Ÿæˆå™¨

6. å·¥å…·æ¨¡å— (arc_synthesis_framework/utils/):
   - __init__.py               # å·¥å…·æ¨¡å—åˆå§‹åŒ–
   - arc_loader.py             # ARCæ•°æ®åŠ è½½å™¨
   - metrics.py                # æ€§èƒ½æŒ‡æ ‡
   - logging.py                # æ—¥å¿—å·¥å…·

7. Popperæ–‡ä»¶ (arc_synthesis_framework/popper_files/):
   - templates/basic_bias.pl   # åŸºæœ¬åç½®æ¨¡æ¿
   - templates/basic_bk.pl     # åŸºæœ¬èƒŒæ™¯çŸ¥è¯†æ¨¡æ¿
   - templates/spatial_bias.pl # ç©ºé—´æ¨ç†åç½®

8. ç¤ºä¾‹æ–‡ä»¶ (examples/):
   - simple_tasks/color_change.json    # ç®€å•é¢œè‰²è½¬æ¢ä»»åŠ¡
   - demonstrations/basic_usage.py     # åŸºæœ¬ä½¿ç”¨æ¼”ç¤º

9. æµ‹è¯•æ–‡ä»¶ (tests/):
   - __init__.py               # æµ‹è¯•æ¨¡å—åˆå§‹åŒ–
   - test_synthesis_engine.py  # åˆæˆå¼•æ“æµ‹è¯•
   - test_object_extractor.py  # å¯¹è±¡æå–å™¨æµ‹è¯•

ä½¿ç”¨è¯´æ˜:
1. å°†ä»£ç ä¿å­˜ä¸ºå¯¹åº”çš„æ–‡ä»¶
2. å®‰è£…ä¾èµ–: pip install -r requirements.txt
3. é…ç½®Popperè·¯å¾„
4. è¿è¡Œæ¼”ç¤º: python main.py --demo
"""

print("=" * 70)
print("ARCç¨‹åºåˆæˆæ¡†æ¶ - å®Œæ•´é¡¹ç›®æ–‡ä»¶åŒ…")
print("=" * 70)
print()
print("æœ¬æ–‡ä»¶åŒ…å«å®Œæ•´çš„é¡¹ç›®ä»£ç ç»“æ„ï¼ŒåŒ…æ‹¬:")
print("âœ… æ ¸å¿ƒåˆæˆå¼•æ“")
print("âœ… Popper ILPé›†æˆ") 
print("âœ… å¯¹è±¡æå–å’Œç©ºé—´åˆ†æ")
print("âœ… CEGISåä¾‹å¼•å¯¼åˆæˆ")
print("âœ… åç»Ÿä¸€æ¨¡å¼æ³›åŒ–")
print("âœ… å®Œæ•´çš„é…ç½®å’Œç¤ºä¾‹")
print("âœ… æµ‹è¯•æ¡†æ¶")
print()
print("ä½¿ç”¨æ–¹æ³•:")
print("1. å¤åˆ¶ç›¸åº”ä»£ç åˆ°å¯¹åº”æ–‡ä»¶")
print("2. æŒ‰ç…§é¡¹ç›®ç»“æ„åˆ›å»ºç›®å½•")
print("3. å®‰è£…ä¾èµ–å¹¶é…ç½®Popper")
print("4. è¿è¡Œæ¼”ç¤ºéªŒè¯å®‰è£…")
print()
print(FILE_LIST)
